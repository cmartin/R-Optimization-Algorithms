X <- c(1.43918707206358, 0.861877340280794, 2.76746138941514, 4.88745671180112,
5.53641254573992, 5.22086144291394, 5.94308640955745, 6.93643760848387,
9.42463552083247, 11.1877809914788, 12.1302052933127, 11.2147715785223,
12.848031992378, 14.3378801303953, 15.3410318471594, 18.5676830808965,
17.8454917308378, 19.1455879257919, 20.0397972030282, 19.7348986429751
)

Y <- c(14.1305975559742, 13.7336322023462, 21.8011051634053, 11.7989845487667,
24.6286759474169, 27.7105857528649, 27.8915722782998, 18.7420147920554,
30.0555135087024, 33.5249382148357, 39.6149670294955, 37.6560889127305,
28.2836475824896, 34.8500919660008, 37.2748088204257, 41.3219628248025,
43.1367380365742, 43.9487287582212, 50.7591342244774, 45.5971708083044
)

# summary(lm(Y~X))

########## With a simple sum of squares
# params = intercept, slope
lm_ss <- function(params) {
    sum(
      (Y - (params[1] + params[2]*X))^2
    )
}

################# With a likelihood function

lm_logL <- function(params) {
  -sum( # likelihood needs to be maximized, but NM minimizes
    dnorm(
      Y,
      params[1] + params[2]*X, # b0 and b1
      params[3], # sigma
      log = TRUE
    )
  )
}
